import joblib
import streamlit as st
import pandas as pd
import re
from preprocessing import preprocess
import matplotlib.pyplot as plt
from wordcloud import WordCloud
# Load the necessary files (emoji, teen, translation, wrong words, stopwords)
# Example of loading emoji and other dictionaries

# Emoji Dictionary
with open('emojicon.txt', 'r', encoding="utf8") as file:
    emoji_lst = file.read().split('\n')
    emoji_dict = {key: str(value) for key, value in (line.split('\t') for line in emoji_lst)}

# Teen code Dictionary
with open('teencode.txt', 'r', encoding="utf8") as file:
    teen_lst = file.read().split('\n')
    teen_dict = {key: str(value) for key, value in (line.split('\t') for line in teen_lst)}

# Wrong words list
with open('wrong-word.txt', 'r', encoding="utf8") as file:
    wrong_lst = file.read().split('\n')

# Stopwords list
with open('vietnamese-stopwords.txt', 'r', encoding="utf8") as file:
    stopwords_lst = file.read().split('\n')

# Load the classification model
# Load the pipeline or classifier that was trained earlier
model = joblib.load('model_pipeline.pkl')

# GUI setup using Streamlit
st.image('hasaki_banner.jpg', use_container_width=True)
st.title("Sentiment Analysis with Hasaki.vn")

# Sidebar menu
menu = ["Business Objective", "New Prediction", "Product Analysis"]
menu_choice = st.sidebar.selectbox('Menu', menu)

# Information in Sidebar
st.sidebar.write("""#### Th√†nh vi√™n th·ª±c hi·ªán:
                 V≈© Trung Ki√™n & Tr·∫ßn Ph∆∞∆°ng Mai""")
st.sidebar.write("""#### Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n: 
                 Khu·∫•t Th√πy Ph∆∞∆°ng""")
st.sidebar.write("""#### Th·ªùi gian th·ª±c hi·ªán: 15/12/2024""")

# Tabs synchronized with Sidebar Menu

## Use the menu selection to highlight the corresponding tab
if menu_choice == "Business Objective":
    st.subheader("Business Objective")
    st.write("""HASAKI.VN l√† h·ªá th·ªëng c·ª≠a h√†ng m·ªπ ph·∫©m ch√≠nh h√£ng v√† d·ªãch v·ª• chƒÉm s√≥c s·∫Øc ƒë·∫πp chuy√™n s√¢u v·ªõi h·ªá th·ªëng c·ª≠a h√†ng tr·∫£i d√†i tr√™n to√†n qu·ªëc; v√† hi·ªán ƒëang l√† ƒë·ªëi t√°c ph√¢n ph·ªëi chi·∫øn l∆∞·ª£c t·∫°i th·ªã tr∆∞·ªùng Vi·ªát Nam c·ªßa h√†ng lo·∫°t th∆∞∆°ng hi·ªáu l·ªõn.""")
    st.write("""T·ª´ nh·ªØng ƒë√°nh gi√° c·ªßa kh√°ch h√†ng, v·∫•n ƒë·ªÅ ƒë∆∞·ª£c ƒë∆∞a ra l√† l√†m sao ƒë·ªÉ c√°c nh√£n h√†ng hi·ªÉu kh√°ch h√†ng r√µ h∆°n, bi·∫øt h·ªç ƒë√°nh gi√° g√¨ v·ªÅ s·∫£n ph·∫©m, t·ª´ ƒë√≥ c√≥ th·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m c≈©ng nh∆∞ c√°c d·ªãch v·ª• ƒëi k√®m.""")
    st.image("sentiment.jpg")
    st.write("=> Problem/ Requirement: X√¢y d·ª±ng h·ªá th·ªëng d·ª±a tr√™n l·ªãch s·ª≠ nh·ªØng ƒë√°nh gi√° c·ªßa kh√°ch h√†ng ƒë√£ c√≥ tr∆∞·ªõc ƒë√≥. D·ªØ li·ªáu ƒë∆∞·ª£c thu th·∫≠p t·ª´ ph·∫ßn b√¨nh lu·∫≠n v√† ƒë√°nh gi√° c·ªßa kh√°ch h√†ng ·ªü Hasaki.vn.")
    st.write("=> X√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n gi√∫p Hasaki.vn v√† c√°c c√¥ng ty ƒë·ªëi t√°c c√≥ th·ªÉ bi·∫øt ƒë∆∞·ª£c nh·ªØng ph·∫£n h·ªìi nhanh ch√≥ng c·ªßa kh√°ch h√†ng v·ªÅ s·∫£n ph·∫©m hay d·ªãch v·ª• (t√≠ch c·ª±c, ti√™u c·ª±c hay trung t√≠nh), ƒëi·ªÅu n√†y gi√∫p h·ªç c·∫£i thi·ªán s·∫£n ph·∫©m/ d·ªãch v·ª• v√† l√†m h√†i l√≤ng kh√°ch h√†ng.")

elif menu_choice == "New Prediction":
        st.subheader("Sentiment Analysis Predictor")
        
        # Add a informative description
        st.markdown("""
        üîç **Predict Sentiment of Customer Reviews**
        - Analyze the emotional tone of text: Positive or Negative
        - Support for Vietnamese language comments
        - Works with single text or multiple comments via file upload
        """)
        
        # Add an example section
        with st.expander("üí° See Example"):
            st.markdown("""
            **Example Inputs:**
            - Positive: "S·∫£n ph·∫©m tuy·ªát v·ªùi, r·∫•t h√†i l√≤ng!"
            - Negative: "Ch·∫•t l∆∞·ª£ng k√©m, kh√¥ng nh∆∞ m√¥ t·∫£"
            """)
        
        input_type = st.radio("Choose Input Method", ["Input Text", "Upload File"], help="Select how you want to input your reviews")
        user_content = None

        if input_type == "Input Text":
            user_content = st.text_area(
                "Enter your content:", 
                placeholder="Nh·∫≠p nh·∫≠n x√©t c·ªßa b·∫°n...",
                help="Nh·∫≠p m·ªôt ho·∫∑c nhi·ªÅu nh·∫≠n x√©t ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c"
            )
            
            # Add some sample buttons
            st.markdown("#### Quick Examples:")
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üåû Positive"):
                    user_content = "S·∫£n ph·∫©m tuy·ªát v·ªùi, r·∫•t h√†i l√≤ng!"
            with col2:
                if st.button("üåßÔ∏è Negative"):
                    user_content = "Ch·∫•t l∆∞·ª£ng k√©m, kh√¥ng nh∆∞ m√¥ t·∫£"

            if user_content.strip():
                user_content = [user_content]  # Convert to list for processing

        elif input_type == "Upload File":
            uploaded_file = st.file_uploader(
                "Upload a CSV or TXT file", 
                type=["csv", "txt"],
                help="Upload a file with multiple reviews. Each line should be a separate review."
            )
            if uploaded_file:
                # Read file as raw text
                raw_text = uploaded_file.read().decode("utf-8")
                user_content = raw_text.splitlines()

        # Perform preprocessing and prediction if content exists
        if user_content:
            st.write("üîÆ Processing your input...")
            processed_content = [
                preprocess(text, emoji_dict, teen_dict, wrong_lst, stopwords_lst)
                for text in user_content
            ]
            predictions = model.predict(processed_content)

            # Display results with color coding
            results_df = pd.DataFrame({"Original Text": user_content, "Prediction": predictions})
            
            # Color mapping for predictions
            def color_prediction(pred):
                if pred == 'üòÑ Positive':
                    return 'background-color: #d4edda; color: #155724;'
                elif pred == 'üòû Negative':
                    return 'background-color: #f8d7da; color: #721c24;'
            
            styled_df = results_df.style.apply(lambda x: [color_prediction(val) for val in x], axis=1)
            
            st.write("### üìä Prediction Results")
            st.dataframe(styled_df, use_container_width=True)
            
            if input_type == "Upload File" and len(user_content) > 1:
                st.write("### üìà Sentiment Distribution")
                sentiment_counts = results_df['Prediction'].value_counts()
                fig, ax = plt.subplots()
                sentiment_counts.plot(kind='pie', autopct='%1.1f%%', colors=['#2ecc71', '#e74c3c'], ax=ax)
                ax.set_title('Overall Sentiment Distribution')
                st.pyplot(fig)

elif menu_choice == 'Product Analysis':
    def load_data():
        df_products = pd.read_csv('San_pham_full.csv')
        df_ratings = pd.read_csv('Danh_gia_full.csv')
        df_ratings_da_xu_ly = pd.read_csv('data_clean_2.csv')
        return df_products, df_ratings, df_ratings_da_xu_ly

    df_products, df_ratings, df_ratings_da_xu_ly = load_data()

    # Function to Display Product Information
    def hien_thi_san_pham(ma_sp):
        try:
            # T√¨m s·∫£n ph·∫©m theo m√£
            san_pham = df_products[df_products['ma_san_pham'] == ma_sp].iloc[0]
            
            # T·∫°o DataFrame ƒë·ªÉ hi·ªÉn th·ªã
            data = {
                'Thu·ªôc t√≠nh': [
                    'M√£ s·∫£n ph·∫©m',
                    'T√™n s·∫£n ph·∫©m',
                    'Gi√° b√°n',
                    'Gi√° g·ªëc',
                    'Ph√¢n lo·∫°i',
                    'M√¥ t·∫£',
                    'ƒêi·ªÉm trung b√¨nh'
                ],
                'Gi√° tr·ªã': [
                    san_pham['ma_san_pham'],
                    san_pham['ten_san_pham'],
                    f"{san_pham['gia_ban']:,.0f} VNƒê",
                    f"{san_pham['gia_goc']:,.0f} VNƒê",
                    san_pham['phan_loai'],
                    san_pham['mo_ta'],
                    f"{san_pham['diem_trung_binh']:.1f}‚≠ê"
                ]
            }
            
            # T·∫°o DataFrame v√† hi·ªÉn th·ªã b·∫±ng streamlit
            df_info = pd.DataFrame(data)
            st.dataframe(
                df_info,
                column_config={
                    "Thu·ªôc t√≠nh": st.column_config.Column(
                        width="medium"
                    ),
                    "Gi√° tr·ªã": st.column_config.Column(
                        width="large"
                    )
                },
                hide_index=True
            )
            
        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")

    # Function to Analyze Ratings
    def analyze_ratings(ma_sp):
        try:
            # Join hai b·∫£ng
            df_merged = pd.merge(df_products, df_ratings, on='ma_san_pham', how='left')
            
            # L·ªçc d·ªØ li·ªáu cho s·∫£n ph·∫©m ƒë∆∞·ª£c ch·ªçn
            product_ratings = df_merged[df_merged['ma_san_pham'] == ma_sp]
            if len(product_ratings) == 0:
                st.error("‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m v·ªõi m√£ n√†y")
                return

            # L·∫•y th√¥ng tin s·∫£n ph·∫©m
            ten_sp = product_ratings['ten_san_pham'].iloc[0]

            # T√≠nh to√°n th·ªëng k√™
            rating_counts = product_ratings['so_sao'].value_counts().sort_index(ascending=False)
            total_ratings = len(product_ratings)
            rating_percentages = (rating_counts / total_ratings * 100).round(1)

            # Plot bi·ªÉu ƒë·ªì
            fig, ax = plt.subplots(1, 2, figsize=(15, 8))

            # C·ªôt
            ax[0].bar(rating_counts.index, rating_counts.values, color='#FFB636')
            ax[0].set_title(f'Ph√¢n b·ªë s·ªë l∆∞·ª£ng ƒë√°nh gi√°\n{ten_sp}')
            ax[0].set_xlabel('S·ªë sao')
            ax[0].set_ylabel('S·ªë l∆∞·ª£ng ƒë√°nh gi√°')

            # Bi·ªÉu ƒë·ªì tr√≤n
            ax[1].pie(rating_percentages.values, labels=[f'{i} sao ({p}%)' for i, p in zip(rating_percentages.index, rating_percentages.values)], autopct='%1.1f%%', colors=['#FFB636', '#FFC75F', '#FFD88C', '#FFE4B3', '#FFF1D7'])
            ax[1].set_title('Ph√¢n b·ªë ph·∫ßn trƒÉm ƒë√°nh gi√°')

            st.pyplot(fig)

            # Hi·ªÉn th·ªã th√¥ng tin t·ªïng quan d∆∞·ªõi d·∫°ng b·∫£ng
            stats_data = {
                'Lo·∫°i ƒë√°nh gi√°': [f"{stars} sao ({'‚≠ê' * int(stars)})" for stars in rating_counts.index],
                'S·ªë l∆∞·ª£ng': rating_counts.values,
                'Ph·∫ßn trƒÉm': [f"{percentage:.1f}%" for percentage in rating_percentages.values]
            }
            
            df_stats = pd.DataFrame(stats_data)
            
            st.write(f"### TH·ªêNG K√ä ƒê√ÅNH GI√Å S·∫¢N PH·∫®M")
            st.write(f"M√£ s·∫£n ph·∫©m: {ma_sp}")
            st.write(f"T√™n s·∫£n ph·∫©m: {ten_sp}")
            
            st.dataframe(
                df_stats,
                column_config={
                    "Lo·∫°i ƒë√°nh gi√°": st.column_config.Column(
                        width="medium"
                    ),
                    "S·ªë l∆∞·ª£ng": st.column_config.NumberColumn(
                        width="small",
                        format="%d"
                    ),
                    "Ph·∫ßn trƒÉm": st.column_config.Column(
                        width="small"
                    )
                },
                hide_index=True
            )
             # Th√™m ph·∫ßn hi·ªÉn th·ªã b√¨nh lu·∫≠n m·∫´u ·ªü ƒë√¢y
            st.write("\n### üìù M·ªôt s·ªë b√¨nh lu·∫≠n c·ªßa kh√°ch h√†ng:")
            reviews_sample = product_ratings[['noi_dung_binh_luan', 'so_sao']].dropna().head(5)
            
            for _, review in reviews_sample.iterrows():
                with st.container():
                    st.markdown(f"""
                        <div style="padding: 10px; border-radius: 5px; background-color: #f0f2f6; margin: 5px 0;">
                            <div style="color: #FFB636;">{"‚≠ê" * int(review.so_sao)}</div>
                            <div style="margin-top: 5px;">{review.noi_dung_binh_luan}</div>
                        </div>
                    """, unsafe_allow_html=True)

        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")

    # Function to Create Sentiment Word Clouds
    def create_sentiment_wordclouds(ma_sp):
        try:
            # Merge data
            df_merged = pd.merge(df_products, df_ratings, on='ma_san_pham', how='left')
            df_merged_2 = pd.merge(df_merged.drop(columns=['noi_dung_binh_luan']), df_ratings_da_xu_ly, on='id', how='left')
            # L·ªçc d·ªØ li·ªáu cho s·∫£n ph·∫©m ƒë∆∞·ª£c ch·ªçn
            product_data = df_merged_2[df_merged_2['ma_san_pham'] == ma_sp]
            if len(product_data) == 0:
                st.error("‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m v·ªõi m√£ n√†y")
                return

            ten_sp = product_data['ten_san_pham'].iloc[0]

            # Wordclouds for sentiment analysis
            sentiment_colors = {'Positive': '#2ecc71', 'Negative': '#e74c3c'}
            fig, axes = plt.subplots(2, 1, figsize=(20, 10))

            for idx, sentiment in enumerate(sentiment_colors.keys()):
                sentiment_comments = product_data[product_data['sentiment'] == sentiment]
                
# Wordclouds for sentiment analysis
            sentiment_colors = {'Positive': '#2ecc71', 'Negative': '#e74c3c'}
            fig, axes = plt.subplots(2, 1, figsize=(20, 10))

            for idx, sentiment in enumerate(sentiment_colors.keys()):
                sentiment_comments = product_data[product_data['sentiment'] == sentiment]
                
                if len(sentiment_comments) > 0:
                    # K·∫øt h·ª£p t·∫•t c·∫£ comment - ƒë√£ s·ª≠a c√°ch g·ªçi h√†m preprocess
                    text = ' '.join(sentiment_comments['noi_dung_binh_luan'].apply(
                        lambda x: preprocess(x, emoji_dict, teen_dict, wrong_lst, stopwords_lst)
                    ))
                    
                    # T·∫°o wordcloud
                    wordcloud = WordCloud(
                        width=800, 
                        height=400, 
                        background_color='white', 
                        max_words=100, 
                        color_func=lambda *args, **kwargs: sentiment_colors[sentiment]
                    ).generate(text)
                    
                    axes[idx].imshow(wordcloud, interpolation='bilinear')
                    axes[idx].axis('off')
                    axes[idx].set_title(f'Wordcloud cho ƒë√°nh gi√° {sentiment.upper()}\n({len(sentiment_comments)} b√¨nh lu·∫≠n)', pad=20, size=15)

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()  # Gi·∫£i ph√≥ng b·ªô nh·ªõ

            # Hi·ªÉn th·ªã th·ªëng k√™ sentiment d∆∞·ªõi d·∫°ng b·∫£ng
            sentiment_counts = product_data['sentiment'].value_counts()
            total_comments = len(product_data)
            
            stats_data = {
                'Lo·∫°i c·∫£m x√∫c': list(sentiment_colors.keys()),
                'S·ªë l∆∞·ª£ng': [sentiment_counts.get(sentiment, 0) for sentiment in sentiment_colors.keys()],
                'Ph·∫ßn trƒÉm': [f"{(sentiment_counts.get(sentiment, 0)/total_comments*100):.1f}%" 
                             if total_comments > 0 else "0%" 
                             for sentiment in sentiment_colors.keys()]
            }
            
            df_stats = pd.DataFrame(stats_data)
            
            st.write(f"### TH·ªêNG K√ä PH√ÇN T√çCH C·∫¢M X√öC B√åNH LU·∫¨N")
            st.write(f"M√£ s·∫£n ph·∫©m: {ma_sp}")
            st.write(f"T√™n s·∫£n ph·∫©m: {ten_sp}")
            st.write(f"T·ªïng s·ªë b√¨nh lu·∫≠n: {total_comments:,d}")  # Th√™m format s·ªë
            
            st.dataframe(
                df_stats,
                column_config={
                    "Lo·∫°i c·∫£m x√∫c": st.column_config.Column(
                        width="medium"
                    ),
                    "S·ªë l∆∞·ª£ng": st.column_config.NumberColumn(
                        width="small",
                        format="%d"
                    ),
                    "Ph·∫ßn trƒÉm": st.column_config.Column(
                        width="small"
                    )
                },
                hide_index=True
            )

        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")

    # # Streamlit UI
    # st.title("·ª®ng D·ª•ng Ph√¢n T√≠ch S·∫£n Ph·∫©m")
    
    # ma_san_pham_input = st.number_input("Nh·∫≠p m√£ s·∫£n ph·∫©m", min_value=0)
    
    # if ma_san_pham_input:
    #     st.subheader("üì¶ TH√îNG TIN S·∫¢N PH·∫®M üì¶")
    #     hien_thi_san_pham(ma_san_pham_input)
        
    #     st.subheader("üìä PH√ÇN T√çCH ƒê√ÅNH GI√Å S·∫¢N PH·∫®M üìä")
    #     analyze_ratings(ma_san_pham_input)

    #     st.subheader("üìä PH√ÇN T√çCH C·∫¢M X√öC B√åNH LU·∫¨N S·∫¢N PH·∫®M üìä")
    #     create_sentiment_wordclouds(ma_san_pham_input)
    # Streamlit UI
    st.title("·ª®ng D·ª•ng Ph√¢n T√≠ch S·∫£n Ph·∫©m")

    # Th√™m search box
    search_keyword = st.text_input("üîç T√¨m ki·∫øm s·∫£n ph·∫©m", placeholder="Nh·∫≠p t√™n s·∫£n ph·∫©m (v√≠ d·ª•: kem)")

    if search_keyword:
        # T√¨m ki·∫øm trong t√™n s·∫£n ph·∫©m, kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng
        mask = df_products['ten_san_pham'].str.contains(search_keyword, case=False, na=False)
        search_results = df_products[mask].copy()
        
        if len(search_results) > 0:
            # T·∫°o c·ªôt hi·ªÉn th·ªã gi√° ƒë√£ format
            search_results['gia_hien_thi'] = search_results['gia_ban'].apply(lambda x: f"{x:,.0f} VNƒê")
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm
            st.write(f"T√¨m th·∫•y {len(search_results)} s·∫£n ph·∫©m:")
            
            # T·∫°o DataFrame ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm
            display_df = search_results[['ma_san_pham', 'ten_san_pham', 'gia_hien_thi', 'diem_trung_binh']].copy()
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi format
            st.dataframe(
                display_df,
                column_config={
                    "ma_san_pham": st.column_config.NumberColumn(
                        "M√£ SP",
                        width="small"
                    ),
                    "ten_san_pham": st.column_config.Column(
                        "T√™n s·∫£n ph·∫©m",
                        width="large"
                    ),
                    "gia_hien_thi": st.column_config.Column(
                        "Gi√° b√°n",
                        width="medium"
                    ),
                    "diem_trung_binh": st.column_config.NumberColumn(
                        "ƒê√°nh gi√° ‚≠ê",
                        width="small",
                        format="%.1f"
                    )
                },
                hide_index=True
            )
            
            # Cho ph√©p ch·ªçn s·∫£n ph·∫©m t·ª´ k·∫øt qu·∫£ t√¨m ki·∫øm
            ma_san_pham_list = search_results['ma_san_pham'].tolist()
            ten_san_pham_list = search_results['ten_san_pham'].tolist()
            
            # T·∫°o danh s√°ch options v·ªõi format "M√£ SP - T√™n SP"
            options = [f"{ma} - {ten}" for ma, ten in zip(ma_san_pham_list, ten_san_pham_list)]
            
            selected_product = st.selectbox(
                "Ch·ªçn s·∫£n ph·∫©m ƒë·ªÉ ph√¢n t√≠ch:",
                options=options,
                format_func=lambda x: x.split(" - ")[1]  # Ch·ªâ hi·ªÉn th·ªã t√™n SP trong dropdown
            )
            
            if selected_product:
                # L·∫•y m√£ s·∫£n ph·∫©m t·ª´ option ƒë√£ ch·ªçn
                ma_san_pham_input = int(selected_product.split(" - ")[0])
                
                # Hi·ªÉn th·ªã c√°c ph√¢n t√≠ch
                st.subheader("üì¶ TH√îNG TIN S·∫¢N PH·∫®M üì¶")
                hien_thi_san_pham(ma_san_pham_input)
                
                st.subheader("üìä PH√ÇN T√çCH ƒê√ÅNH GI√Å S·∫¢N PH·∫®M üìä")
                analyze_ratings(ma_san_pham_input)

                st.subheader("üìä PH√ÇN T√çCH C·∫¢M X√öC B√åNH LU·∫¨N S·∫¢N PH·∫®M üìä")
                create_sentiment_wordclouds(ma_san_pham_input)
        else:
            st.warning(f"Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o v·ªõi t·ª´ kh√≥a: {search_keyword}")
    else:
        st.info("üëÜ Nh·∫≠p t·ª´ kh√≥a ƒë·ªÉ t√¨m ki·∫øm s·∫£n ph·∫©m")
